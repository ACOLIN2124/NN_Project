{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"https://javier.rodriguez.org.mx/itesm/2014/tecnologico-de-monterrey-blue.png\" width=\"450\" align=\"center\"></center>\n",
    "<br><p><center><h1><b>Object Detection with Neural Network Appraoch: Analyzing the Stanford Cars Dataset</b></h1></center></p> \n",
    "<p><center><h3>Course: <i>Neural Network Design and Deep Learning</i></h3></center></p>\n",
    "<p><center><h4>Instructed by: <i>Dr. Leonardo Mauricio Cañete Sifuentes</i></h4></center></p> \n",
    "\n",
    "<p style=\"text-align: right;\">Alejandro Santiago Baca Eyssautier - A01656580</p> \n",
    "<p style=\"text-align: right;\">André Colín Avila - A01657474</p> \n",
    "<p style=\"text-align: right;\">Santiago Caballero - A01657699</p> \n",
    "<p style=\"text-align: right;\">November 28th, 2024</p><br>\n",
    "\n",
    "<br><p><h3> <b>1. Introduction</b></h3></p>\n",
    "\n",
    "The objective of this project is to explore object detection using neural networks by analyzing the **Stanford Cars Dataset**. This dataset is widely used for fine-grained visual categorization, making it an excellent choice for detecting and classifying cars into various categories based on their make, model, and year. \n",
    "\n",
    "Throughout this project, the team aims to preprocess the data, construct multiple neural network architectures, and evaluate their performance to identify the most efficient and accurate model. The project is divided into individual and team contributions, ensuring a collaborative yet personalized approach to model development.\n",
    "\n",
    "By leveraging deep learning techniques, the team seeks to tackle the challenges of detecting subtle differences between visually similar objects while maintaining computational efficiency.\n",
    "\n",
    "<br>\n",
    "\n",
    "<br><p><h3> <b>2. Dataset Selection and Justification</b></h3></p>\n",
    "\n",
    "The **Stanford Cars Dataset** consists of 16,185 images of cars categorized into 196 classes based on their make, model, and year. The dataset is split into 8,144 training images and 8,041 test images. It is commonly used for fine-grained image classification and object detection tasks.\n",
    "\n",
    "**Key Features:**\n",
    "\n",
    "- **Name**: Stanford Cars Dataset\n",
    "- **Download URL**: [Stanford Cars Dataset on Papers with Code](https://paperswithcode.com/dataset/stanford-cars)\n",
    "- **Description**: The images are provided in high resolution, enabling detailed feature extraction. With 196 classes, the dataset provides a challenging environment for distinguishing between visually similar classes. Bounding boxes and class labels are included, making it suitable for object detection and classification tasks.\n",
    "\n",
    "**Justification**  \n",
    "\n",
    "The Stanford Cars Dataset is an ideal choice for this project for several reasons:\n",
    "\n",
    "1. **Problem Relevance**: The dataset aligns with the team's objective of solving an object detection problem. Its detailed annotations support both object localization and classification tasks.\n",
    "2. **Complexity**: The fine-grained nature of the dataset presents a significant challenge, requiring advanced neural network architectures to achieve high performance.\n",
    "3. **Broad Applicability**: Insights gained from working on this dataset can be extended to other fine-grained object detection problems, such as species identification or defect detection in industrial processes.\n",
    "\n",
    "<br>\n",
    "\n",
    "<br><p><h3> <b>3. Data Preprocessing and Splitting</b></h3></p>\n",
    "\n",
    "The dataset is loaded using the **Hugging Face `datasets` library**, which provides a convenient way to access and manipulate datasets. The **Stanford Cars Dataset** has predefined splits for training, testing, and several additional subsets with distortions such as noise and blur. \n",
    "\n",
    "The project focuses on the **training** and **test** splits for building and evaluating the models, with a portion of the training set used for validation.\n",
    "\n",
    "**Preprocessing Steps**\n",
    "\n",
    "1. **Image Resizing**: Images are resized to a fixed resolution ($224 \\times 224$) to ensure compatibility with deep learning models.\n",
    "2. **Normalization**: Pixel values are normalized to the range [0, 1] to stabilize the training process.\n",
    "3. **Data Augmentation**: Techniques such as flipping and rotation are applied to the training set to improve generalization.\n",
    "4. **Dataset Splitting**:\n",
    "   - The training set is further split into **training** (80%) and **validation** (20%) subsets for hyperparameter tuning and model evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['image', 'label'],\n",
      "        num_rows: 8144\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['image', 'label'],\n",
      "        num_rows: 8041\n",
      "    })\n",
      "    contrast: Dataset({\n",
      "        features: ['image', 'label'],\n",
      "        num_rows: 8041\n",
      "    })\n",
      "    gaussian_noise: Dataset({\n",
      "        features: ['image', 'label'],\n",
      "        num_rows: 8041\n",
      "    })\n",
      "    impulse_noise: Dataset({\n",
      "        features: ['image', 'label'],\n",
      "        num_rows: 8041\n",
      "    })\n",
      "    jpeg_compression: Dataset({\n",
      "        features: ['image', 'label'],\n",
      "        num_rows: 8041\n",
      "    })\n",
      "    motion_blur: Dataset({\n",
      "        features: ['image', 'label'],\n",
      "        num_rows: 8041\n",
      "    })\n",
      "    pixelate: Dataset({\n",
      "        features: ['image', 'label'],\n",
      "        num_rows: 8041\n",
      "    })\n",
      "    spatter: Dataset({\n",
      "        features: ['image', 'label'],\n",
      "        num_rows: 8041\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "# Load the dataset\n",
    "dataset = load_dataset(\"tanganke/stanford_cars\")\n",
    "\n",
    "# Display dataset structure\n",
    "print(dataset)\n",
    "\n",
    "# Access training and test sets\n",
    "train_set = dataset[\"train\"]\n",
    "test_set = dataset[\"test\"]\n",
    "\n",
    "# Define preprocessing pipeline\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize images\n",
    "    transforms.ToTensor(),          # Convert images to tensors\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  # Normalize pixel values\n",
    "])\n",
    "\n",
    "# Apply transformations to dataset\n",
    "train_set = train_set.with_transform(lambda example: {\n",
    "    \"image\": transform(example[\"image\"]),\n",
    "    \"label\": example[\"label\"]\n",
    "})\n",
    "\n",
    "test_set = test_set.with_transform(lambda example: {\n",
    "    \"image\": transform(example[\"image\"]),\n",
    "    \"label\": example[\"label\"]\n",
    "})\n",
    "\n",
    "# Split training set into training and validation\n",
    "train_size = int(0.8 * len(train_set))\n",
    "val_size = len(train_set) - train_size\n",
    "train_set, val_set = random_split(train_set, [train_size, val_size])\n",
    "\n",
    "# Create DataLoaders for batching\n",
    "train_loader = DataLoader(train_set, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_set, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_set, batch_size=32, shuffle=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
